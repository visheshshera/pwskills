{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 1) What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 1)A parameter refers to a value that is learned by the model during the training process. These parameters define the behavior and performance of the model. They are adjusted based on the training data to help the model make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 2) What is correlation?What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 2)Correlation is a statistical measure that expresses the extent to which two variables are linearly related. It indicates whether an increase in one variable leads to an increase or decrease in another variable and the strength of this relationship.\n",
    "\n",
    "Correlation coefficient is a value that ranges from -1 to 1:\n",
    "1 indicates a perfect positive correlation (as one variable increases, the other increases proportionally).\n",
    "0 indicates no correlation (no linear relationship between the variables).\n",
    "-1 indicates a perfect negative correlation (as one variable increases, the other decreases proportionally)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 3) Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 3)Machine Learning (ML) is a subset of Artificial Intelligence (AI) that allows computers to learn from data and make decisions or predictions without being explicitly programmed. It involves using algorithms and statistical models to find patterns or insights in data, which can then be used to make informed predictions or decisions based on new, unseen data.\n",
    "\n",
    "1. Data\n",
    "2. Features (Input Variables)\n",
    "3. Model (Algorithm)\n",
    "4. Training\n",
    "5. Loss Function\n",
    "6. Evaluation (Testing)\n",
    "7. Hyperparameters\n",
    "8. Optimization\n",
    "9. Evaluation Metrics\n",
    "10. Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 4) How does loss value help in determining whether the model is good or not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 4) Loss Function:\n",
    "\n",
    "The loss function (also called cost function or objective function) measures how well the model’s predictions match the true outcomes. It calculates the error or difference between predicted and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 5) What are continuous and categorical variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 5)\n",
    "\n",
    "1. Continuous variables are numerical variables that can take on any value within a range. These values are often measured and can be represented with decimal points, allowing for infinite precision.\n",
    "\n",
    "Examples:\n",
    "Height: 170.2 cm, 172.5 cm.\n",
    "\n",
    "2. Categorical Variables\n",
    "Categorical variables represent data that can be divided into distinct groups or categories. These variables usually take on a limited number of possible values.\n",
    "\n",
    "Examples:\n",
    "Nominal (No inherent order):\n",
    "Gender: Male, Female.\n",
    "Color: Red, Blue, Green.\n",
    "\n",
    "Ordinal (Has a logical order):\n",
    "Education Level: High School, Bachelor’s, Master’s.\n",
    "Rating: Poor, Average, Good, Excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 6) How do we handle categorical variables in Machine Learning? What are the common techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 6)Categorical variables need to be transformed into numerical formats because most machine learning models can only work with numeric data. This process involves encoding or converting the categories into meaningful representations while preserving their inherent structure (if applicable).\n",
    "\n",
    "1. Label Encoding\n",
    "2. One-Hot Encoding\n",
    "3. Ordinal Encoding\n",
    "etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 7) What do you mean by training and testing a dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 7)1. Training a Dataset\n",
    "Training refers to the process where the machine learning model learns from the training data to understand patterns and relationships between the input features and the target variable (output). During this phase, the model is optimized to minimize the error in its predictions using the training data.\n",
    "\n",
    "2. Testing a Dataset\n",
    "Testing is the process of evaluating the model’s performance on a test dataset, which is data that the model has never seen during training. The test set is used to estimate how well the model will perform on real-world, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 8) What is sklearn.preprocessing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 8)sklearn.preprocessing is a module in the Scikit-learn library that provides tools to preprocess and transform data before feeding it into machine learning models. Data preprocessing is a crucial step in the machine learning pipeline, as raw data often contains noise, inconsistencies, or varying scales that can negatively impact model performance.\n",
    "\n",
    "commonly used methods in sklearn.preprocessing\n",
    "StandardScaler\n",
    "OneHotEncoder\n",
    "OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 9) What is a Test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 9)A test set is a subset of data that is used to evaluate the performance of a machine learning model after it has been trained.The test set should be kept separate from both the training and validation sets to ensure that the evaluation is unbiased and reflects how the model will perform on new, real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 10) How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 10)When you approach a Machine Learning problem, the goal is typically to build a model that can make accurate predictions on unseen data.\n",
    "\n",
    "\n",
    "General Approach to Solving a Machine Learning Problem\n",
    "\n",
    "Define the Problem\n",
    "\n",
    "1. Collect and Prepare Data\n",
    "\n",
    "2. Split the Data\n",
    "\n",
    "3. Choose a Model\n",
    "\n",
    "4. Train the Model\n",
    "\n",
    "5. Evaluate the Model\n",
    "\n",
    "6. Test the Model\n",
    "\n",
    "7. Deploy the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 11) Why do we have to perform EDA before fitting a model to the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 11)(EDA) is a crucial step in the data analysis process that involves inspecting and understanding the dataset before applying machine learning models. The purpose of EDA is to summarize the main characteristics of the dataset, uncover patterns, detect anomalies, test assumptions, and check for relationships between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 12) What is correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 12)Correlation is a statistical measure that expresses the extent to which two variables are linearly related. It indicates whether an increase in one variable leads to an increase or decrease in another variable and the strength of this relationship.\n",
    "\n",
    "Correlation coefficient is a value that ranges from -1 to 1:\n",
    "1 indicates a perfect positive correlation (as one variable increases, the other increases proportionally).\n",
    "0 indicates no correlation (no linear relationship between the variables).\n",
    "-1 indicates a perfect negative correlation (as one variable increases, the other decreases proportionally)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 13) What does negative correlation mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 13)negative correlation indicates a perfect negative correlation (as one variable increases, the other decreases proportionally)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 14) How can you find correlation between variables in Python?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 14)\n",
    "1. Using Pandas' corr() Method\n",
    "    correlation_matrix = df.corr()\n",
    "2. Using Numpy's corrcoef() Function\n",
    "3. Using Seaborn's Heatmap for Visual Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 15) What is causation? Explain difference between correlation and causation with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 15)Causation refers to a cause-and-effect relationship between two variables, where one variable (the cause) directly influences or produces a change in the other variable (the effect). In simple terms, causation implies that one event or variable is responsible for causing the other event or variable to happen.\n",
    "\n",
    "Difference Between Correlation and Causation\n",
    "1. Correlation:\n",
    "Correlation refers to a statistical relationship between two variables where they move together (either positively or negatively), but it doesn't imply that one variable causes the other to change.\n",
    "It simply means that when one variable changes, the other tends to change as well (but the direction of change doesn't matter, and the change may not be directly caused by the other variable).\n",
    "Correlation tells us how two variables are related, but not why they are related.\n",
    "\n",
    "2. Causation:\n",
    "Causation means that one variable directly causes the other variable to change. There is a cause-and-effect relationship.\n",
    "If there is causation, the change in one variable will result in a change in another, and there is a clear direction of influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 16) What is an Optimizer? What are different types of optimizers? Explain each with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 16)In machine learning, particularly in deep learning and neural networks, an optimizer is an algorithm used to minimize (or maximize) the loss function during the training process. The primary goal of the optimizer is to adjust the model's parameters (such as weights and biases) in such a way that the model's predictions become more accurate over time by minimizing the error (or loss).\n",
    "\n",
    "\n",
    "1. Gradient Descent (GD)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "**Example: Using Stochastic Gradient Descent for a simple classification task**\n",
    "\n",
    "model = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "2. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "**Example: SGD for linear classification**\n",
    "\n",
    "sgd_model = SGDClassifier(loss='hinge', max_iter=1000)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "3. Mini-Batch Gradient Descent\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "**Example: Using Mini-batch Gradient Descent for neural network training**\n",
    "\n",
    "mlp_model = MLPClassifier(batch_size=32, max_iter=1000)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "4. Momentum-based Gradient Descent\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "**Example: SGD with Momentum for classification**\n",
    "\n",
    "sgd_momentum_model = SGDClassifier(loss='log', momentum=0.9, max_iter=1000)\n",
    "sgd_momentum_model.fit(X_train, y_train)\n",
    "\n",
    "5. RMSprop (Root Mean Square Propagation)\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "**Example: Using RMSprop in Keras**\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "6. Adam (Adaptive Moment Estimation)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "**Example: Using Adam optimizer in Keras**\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "7. Adagrad\n",
    "\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "**Example: Using Adagrad optimizer in Keras**\n",
    "\n",
    "optimizer = Adagrad(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 17) What is sklearn.linear_model ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 17)sklearn.linear_model is a module in the Scikit-learn library that provides a wide range of algorithms for solving linear regression, classification, and related problems. These algorithms are based on linear models, where the relationship between the input features and the target variable is modeled as a linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 18) What does model.fit() do? What arguments must be given?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 18)The .fit() method in Scikit-learn is used to train a machine learning model. It takes the input data (features) and the target data (labels) and adjusts the model's internal parameters to minimize the error and learn the relationship between the input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 19) What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 19)In machine learning, model.predict() is a method used to make predictions on unseen (test) data once a model has been trained. It uses the patterns and relationships it learned from the training data to predict the outputs (labels) for new inputs.\n",
    "\n",
    "parameters:\n",
    "1. Input Features (X)\n",
    "2. Shape of Input:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 20) What are continuous and categorical variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 20)\n",
    "1. Continuous variables are numerical variables that can take on any value within a range. These values are often measured and can be represented with decimal points, allowing for infinite precision.\n",
    "\n",
    "Examples:\n",
    "Height: 170.2 cm, 172.5 cm.\n",
    "\n",
    "2. Categorical Variables\n",
    "Categorical variables represent data that can be divided into distinct groups or categories. These variables usually take on a limited number of possible values.\n",
    "\n",
    "Examples:\n",
    "Nominal (No inherent order):\n",
    "Gender: Male, Female.\n",
    "Color: Red, Blue, Green.\n",
    "\n",
    "Ordinal (Has a logical order):\n",
    "Education Level: High School, Bachelor’s, Master’s.\n",
    "Rating: Poor, Average, Good, Excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 21) What is feature scaling? How does it help in Machine Learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 21) Feature Scaling refers to the process of normalizing or standardizing the range of features (input variables) in a dataset. The goal of feature scaling is to transform features so that they have similar ranges or distributions, ensuring that no single feature dominates others due to differences in scale. It is particularly important for machine learning algorithms that rely on distance or gradient-based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 22) How do we perform scaling in Python?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 22)\n",
    "1. Using Scikit-learn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Example dataset\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax = scaler_minmax.fit_transform(data)\n",
    "print(\"Min-Max Scaled Data:\")\n",
    "print(data_minmax)\n",
    "\n",
    "# Standardization (Z-score)\n",
    "scaler_standard = StandardScaler()\n",
    "data_standard = scaler_standard.fit_transform(data)\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(data_standard)\n",
    "\n",
    "# Robust Scaling\n",
    "scaler_robust = RobustScaler()\n",
    "data_robust = scaler_robust.fit_transform(data)\n",
    "print(\"\\nRobust Scaled Data:\")\n",
    "print(data_robust)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 23) What is sklearn.preprocessing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 23)sklearn.preprocessing is a module in the Scikit-learn library that provides tools to preprocess and transform data before feeding it into machine learning models. Data preprocessing is a crucial step in the machine learning pipeline, as raw data often contains noise, inconsistencies, or varying scales that can negatively impact model performance.\n",
    "\n",
    "commonly used methods in sklearn.preprocessing\n",
    "StandardScaler\n",
    "OneHotEncoder\n",
    "OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 24) How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 24)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])  \n",
    "y = np.array([0, 1, 0, 1, 0])  # Target labels (for classification)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Features:\")\n",
    "print(X_train)\n",
    "print(\"Testing Features:\")\n",
    "print(X_test)\n",
    "\n",
    "print(\"Training Labels:\")\n",
    "print(y_train)\n",
    "print(\"Testing Labels:\")\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUES 25) Explain data encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 25)Data encoding is the process of converting data into a machine-readable format. It is particularly important when working with categorical variables in machine learning, as most algorithms require numeric input to process the data effectively."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
