{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****REGRESSION MODULE 3 ASSIGNMENT****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 1)  - What is Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 1) - Simple Linear Regression is a ml model to determine the relationship between one independent and one deependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 2)  - What are the key assumptions of Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 2)\n",
    "\n",
    "1. **Linearity**: The relationship between the independent variable and the dependent variable is linear.\n",
    "\n",
    "2. **Independence**: The observations are independent of each other. This means that the residuals (errors) are not correlated with each other.\n",
    "\n",
    "3. **Homoscedasticity**: The variance of the residuals is constant across all levels of the independent variable. This means that the spread of the residuals is the same for all predicted values.\n",
    "\n",
    "4. **Normality**: The residuals of the model are normally distributed. This assumption is important for hypothesis testing and constructing confidence intervals.\n",
    "\n",
    "5. **No Multicollinearity**: The independent variable is not highly correlated with other variables. This is less of a concern in Simple Linear Regression as there is only one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 3)  - What does the coefficient m represent in the equation Y=mX+c?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 3) - The slope of the line, which indicates the rate of change of ( Y ) with respect to ( X ). It tells you how much ( Y ) changes for a unit change in ( X )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 4)  - What does the intercept c represent in the equation Y=mX+c?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 4) - In a practical context, if you were predicting a value based on some input, the intercept ( c ) would be the baseline value of your prediction when the input is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 5)  - How do we calculate the slope m in Simple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 5) - \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "print(f\"slope of equation={regressor.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 6)  - What is the purpose of the least squares method in Simple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 6) - The least squares method in Simple Linear Regression is used to find the best-fitting line through a set of data points. The purpose of this method is to minimize the sum of the squared differences (errors) between the observed values and the values predicted by the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 7)  - How is the coefficient of determination (R²) interpreted in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 7) - The coefficient of determination, denoted as R², is a key metric in Simple Linear Regression. It provides a measure of how well the independent variable(s) explain the variability of the dependent variable. Here's a detailed interpretation:\n",
    "\n",
    "Definition: R² is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "Range: R² values range from 0 to 1.\n",
    "\n",
    "R² = 0: Indicates that the independent variable(s) do not explain any of the variability of the dependent variable.\n",
    "R² = 1: Indicates that the independent variable(s) explain all the variability of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 8)  - What is Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 8) - Multiple Linear Regression is a statistical technique that models the relationship between two or more independent variables and a dependent variable by fitting a linear equation to the observed data. It extends Simple Linear Regression by allowing for multiple predictors, which can provide a more accurate and comprehensive understanding of the factors influencing the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 9)  - What is the main difference between Simple and Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 9) - The main difference between Simple and Multiple Linear Regression is the number of independent variables used in the model. Simple Linear Regression involves one independent variable and one dependent variable, while Multiple Linear Regression involves two or more independent variables and one dependent variable. This allows Multiple Linear Regression to account for the influence of multiple factors on the dependent variable, potentially providing a more accurate and comprehensive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 10) - What are the key assumptions of Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 10) - The key assumptions of Multiple Linear Regression are:\n",
    "\n",
    "1. **Linearity**: The relationship between the dependent variable and each independent variable is linear.\n",
    "\n",
    "2. **Independence**: The observations are independent of each other. This means that the residuals (errors) are not correlated with each other.\n",
    "\n",
    "3. **Homoscedasticity**: The variance of the residuals is constant across all levels of the independent variables. This means that the spread of the residuals is the same for all predicted values.\n",
    "\n",
    "4. **Normality**: The residuals of the model are normally distributed. This assumption is important for hypothesis testing and constructing confidence intervals.\n",
    "\n",
    "5. **No Multicollinearity**: The independent variables are not highly correlated with each other. High multicollinearity can make it difficult to estimate the coefficients of the model accurately.\n",
    "\n",
    "6. **No Autocorrelation**: The residuals are not correlated with each other. This is particularly important in time series data.\n",
    "\n",
    "By ensuring that these assumptions are met, the Multiple Linear Regression model can provide reliable and valid results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 11) - What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 11) - Heteroscedasticity refers to the circumstance in which the variability of the errors in a regression model is not constant across all levels of the independent variables. In other words, the spread or \"scatter\" of the residuals varies at different levels of the independent variable(s).\n",
    "\n",
    "Heteroscedasticity can affect the results of a Multiple Linear Regression model in several ways:\n",
    "1. It can lead to inefficient estimates of the regression coefficients, as the ordinary least squares (OLS) method assumes constant variance of the errors.\n",
    "2. It can result in biased standard errors, which in turn affects the confidence intervals and hypothesis tests, potentially leading to incorrect conclusions about the significance of the predictors.\n",
    "3. It can reduce the overall reliability and validity of the model's predictions.\n",
    "\n",
    "To address heteroscedasticity, various techniques such as transforming the dependent variable, using weighted least squares, or applying robust standard errors can be employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 12) - How can you improve a Multiple Linear Regression model with high multicollinearity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 12) - To improve a Multiple Linear Regression model with high multicollinearity, you can use the following techniques:\n",
    "\n",
    "1. **Remove Highly Correlated Predictors**: Identify and remove predictors that are highly correlated with each other. This can be done using correlation matrices or variance inflation factor (VIF) analysis.\n",
    "\n",
    "2. **Principal Component Analysis (PCA)**: Use PCA to transform the correlated predictors into a smaller set of uncorrelated components. These components can then be used as predictors in the regression model.\n",
    "\n",
    "3. **Ridge Regression**: Apply ridge regression, which adds a penalty term to the regression equation to shrink the coefficients of correlated predictors. This helps to reduce the impact of multicollinearity.\n",
    "\n",
    "4. **Lasso Regression**: Apply lasso regression, which adds a penalty term that can shrink some coefficients to zero, effectively performing variable selection and reducing multicollinearity.\n",
    "\n",
    "5. **Partial Least Squares (PLS) Regression**: Use PLS regression, which combines features of PCA and multiple linear regression to handle multicollinearity by extracting a set of orthogonal factors.\n",
    "\n",
    "6. **Domain Knowledge**: Use domain knowledge to combine or transform correlated predictors into a single predictor that captures the underlying relationship.\n",
    "\n",
    "7. **Increase Sample Size**: Increasing the sample size can help to mitigate the effects of multicollinearity, as it provides more information for estimating the regression coefficients.\n",
    "\n",
    "By applying these techniques, you can improve the stability and interpretability of your Multiple Linear Regression model in the presence of high multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 13) - What are some common techniques for transforming categorical variables for use in regression models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 13) - Some common techniques for transforming categorical variables for use in regression models include:\n",
    "\n",
    "1. **One-Hot Encoding**: This technique converts categorical variables into a series of binary variables (0 or 1). Each category is represented by a separate binary variable. This is useful when the categorical variable is nominal (i.e., no inherent order).\n",
    "\n",
    "2. **Label Encoding**: This technique assigns a unique integer to each category. This is useful when the categorical variable is ordinal (i.e., has an inherent order). However, it can introduce unintended ordinal relationships if used with nominal variables.\n",
    "\n",
    "3. **Binary Encoding**: This technique combines the properties of one-hot encoding and label encoding. Each category is first label encoded, and then the integer is converted into binary code. Each binary digit is represented by a separate column.\n",
    "\n",
    "4. **Target Encoding**: This technique replaces each category with the mean of the target variable for that category. This can be useful when there is a strong relationship between the categorical variable and the target variable, but it can also lead to overfitting.\n",
    "\n",
    "5. **Frequency Encoding**: This technique replaces each category with the frequency of that category in the dataset. This can be useful when the frequency of occurrence of a category is important for the prediction.\n",
    "\n",
    "6. **Ordinal Encoding**: This technique assigns a unique integer to each category based on the order of the categories. This is useful when the categorical variable is ordinal.\n",
    "\n",
    "Each of these techniques has its own advantages and disadvantages, and the choice of technique depends on the nature of the categorical variable and the specific requirements of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 14) - What is the role of interaction terms in Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 14) - Interaction terms in Multiple Linear Regression are used to capture the effect of two or more variables interacting with each other on the dependent variable. These terms allow the model to account for situations where the effect of one independent variable on the dependent variable depends on the level of another independent variable. By including interaction terms, the model can provide a more accurate representation of the relationships between variables and improve the predictive power of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 15) - How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 15) - In Simple Linear Regression, the intercept represents the expected value of the dependent variable when the independent variable is zero. It is the point where the regression line crosses the Y-axis.\n",
    "\n",
    "In Multiple Linear Regression, the interpretation of the intercept is similar, but it represents the expected value of the dependent variable when all the independent variables are zero. However, this interpretation can be less meaningful if the independent variables do not have a meaningful zero point or if the combination of all independent variables being zero is not realistic in the context of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 16) - What is the significance of the slope in regression analysis, and how does it affect predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 16) - The slope in regression analysis represents the rate of change of the dependent variable with respect to the independent variable. It indicates how much the dependent variable is expected to increase (or decrease) when the independent variable increases by one unit. The slope is a crucial component of the regression equation, as it directly affects the predictions made by the model. A positive slope indicates a positive relationship between the variables, while a negative slope indicates a negative relationship. The magnitude of the slope determines the strength of this relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 17) - How does the intercept in a regression model provide context for the relationship between variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 17) - The intercept in a regression model provides context for the relationship between variables by indicating the expected value of the dependent variable when all the independent variables are zero. It serves as a baseline or starting point for the predictions made by the model. The intercept helps to understand the level of the dependent variable in the absence of the influence of the independent variables, providing a reference point for interpreting the effect of the independent variables on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 18) - What are the limitations of using R² as a sole measure of model performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 18) - The limitations of using R² as a sole measure of model performance include:\n",
    "\n",
    "1. **Overfitting**: A high R² value can sometimes indicate overfitting, especially in models with many predictors. Overfitting occurs when the model captures noise in the data rather than the underlying relationship, leading to poor generalization to new data.\n",
    "\n",
    "2. **Ignoring Model Complexity**: R² does not account for the complexity of the model. A more complex model with more predictors can have a higher R², but this does not necessarily mean it is a better model. Adjusted R² and other criteria like AIC or BIC are better suited for comparing models with different numbers of predictors.\n",
    "\n",
    "3. **No Information on Bias**: R² does not provide information about the bias of the model. A model with a high R² can still be biased if it systematically overestimates or underestimates the dependent variable.\n",
    "\n",
    "4. **Not Suitable for Non-Linear Relationships**: R² assumes a linear relationship between the independent and dependent variables. It may not be an appropriate measure for models that capture non-linear relationships.\n",
    "\n",
    "5. **Does Not Reflect Predictive Power**: A high R² does not necessarily mean that the model has good predictive power. It only indicates how well the model fits the training data, not how well it will perform on unseen data.\n",
    "\n",
    "6. **Insensitive to the Scale of the Dependent Variable**: R² is a relative measure and does not provide information about the absolute size of the errors. Two models with the same R² can have very different error magnitudes.\n",
    "\n",
    "7. **Does Not Account for the Quality of Predictors**: R² does not consider the quality or relevance of the predictors. A model with irrelevant predictors can still have a high R².\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 19) - How would you interpret a large standard error for a regression coefficient?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 19) - A large standard error for a regression coefficient indicates that there is a high level of variability in the estimate of that coefficient. This can be interpreted in several ways:\n",
    "\n",
    "**Uncertainty in the Estimate**: A large standard error suggests that the estimate of the regression coefficient is not precise. This means that if you were to take multiple samples and fit the regression model to each, the estimated coefficient would vary widely from sample to sample.\n",
    "\n",
    "**Potential Multicollinearity**: If the predictors in the regression model are highly correlated with each other (multicollinearity), it can inflate the standard errors of the coefficients. This makes it difficult to determine the individual effect of each predictor.\n",
    "\n",
    "**Small Sample Size**: A small sample size can lead to large standard errors because there is less information available to accurately estimate the coefficient.\n",
    "\n",
    "**High Variability in the Data**: If the data itself is highly variable, this can also lead to larger standard errors.\n",
    "\n",
    "In summary, a large standard error indicates that there is considerable uncertainty about the true value of the regression coefficient, which can affect the reliability and interpretability of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 20) - How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 20) - Heteroscedasticity can be identified in residual plots by examining the spread of the residuals (errors) across different levels of the independent variable(s). In a residual plot, the residuals are plotted on the y-axis, and the predicted values or the independent variable are plotted on the x-axis. If the residuals display a pattern, such as a funnel shape (widening or narrowing spread), this indicates heteroscedasticity.\n",
    "\n",
    "It is important to address heteroscedasticity because it violates one of the key assumptions of regression analysis, which is that the variance of the residuals should be constant across all levels of the independent variable(s). Heteroscedasticity can lead to several issues:\n",
    "\n",
    "1. **Inefficient Estimates**: The ordinary least squares (OLS) method assumes constant variance of the residuals. Heteroscedasticity can result in inefficient estimates of the regression coefficients.\n",
    "\n",
    "2. **Biased Standard Errors**: Heteroscedasticity can lead to biased standard errors, which affects the confidence intervals and hypothesis tests. This can result in incorrect conclusions about the significance of the predictors.\n",
    "\n",
    "3. **Reduced Reliability**: The overall reliability and validity of the model's predictions can be compromised due to heteroscedasticity.\n",
    "\n",
    "To address heteroscedasticity, various techniques can be employed, such as transforming the dependent variable, using weighted least squares, or applying robust standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 21) - What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 21) - If a Multiple Linear Regression model has a high R² but a low adjusted R², it suggests that the model may be overfitting the data. \n",
    "\n",
    "R² measures the proportion of the variance in the dependent variable that is predictable from the independent variables. A high R² indicates that the model explains a large portion of the variance in the dependent variable.\n",
    "\n",
    "However, adjusted R² adjusts for the number of predictors in the model and only increases if the new predictor improves the model more than would be expected by chance. A low adjusted R² compared to R² indicates that some of the predictors may not be contributing meaningful information to the model and that the model may be fitting the noise in the data rather than the underlying relationship. This can lead to poor generalization to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 22) - Why is it important to scale variables in Multiple Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 22) - In Multiple Linear Regression, scaling variables is important for several reasons:\n",
    "\n",
    "Improves Convergence: Many optimization algorithms, such as gradient descent, perform better and converge faster when the features are on a similar scale. If the features have vastly different scales, the algorithm might take longer to find the optimal solution.\n",
    "\n",
    "Prevents Dominance: Features with larger scales can dominate the regression coefficients, making it difficult to understand the true impact of each feature. Scaling ensures that each feature contributes equally to the model.\n",
    "\n",
    "Reduces Numerical Instability: Large differences in feature scales can lead to numerical instability and inaccuracies in the calculations, especially when dealing with matrix operations.\n",
    "\n",
    "Enhances Interpretability: When features are scaled, the regression coefficients can be more easily compared to understand the relative importance of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 23) - What is polynomial regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 23) - Polynomial regression is a type of regression analysis in which the relationship between the independent variable X and the dependent variable Y is modeled as an nth degree polynomial. It extends linear regression by allowing for the possibility that the relationship between the variables is non-linear. The general form of a polynomial regression model is:\n",
    "\n",
    "Y = b0 + b1*X + b2*X^2 + ... + bi*X^i\n",
    "\n",
    "where `i` is the degree of the polynomial, and b0, b1, ..., bi are the coefficients of the polynomial terms. Polynomial regression can capture more complex patterns in the data compared to linear regression, but it also increases the risk of overfitting, especially with higher-degree polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "source": [
    "Ans 23) - Polynomial regression is a type of regression analysis in which the relationship between the independent variable X and the dependent variable Y is modeled as an nth degree polynomial. It extends linear regression by allowing for the possibility that the relationship between the variables is non-linear. The general form of a polynomial regression model is:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 24) - How does polynomial regression differ from linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 24) - Polynomial regression differs from linear regression in that it models the relationship between the independent variable(s) and the dependent variable as an nth degree polynomial, rather than a straight line. While linear regression assumes a linear relationship between the variables, polynomial regression can capture non-linear relationships by including higher-order terms of the independent variable(s). This allows polynomial regression to fit more complex patterns in the data, but it also increases the risk of overfitting, especially with higher-degree polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 25) - When is polynomial regression used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 25) - Polynomial regression is used when the relationship between the independent variable and the dependent variable is non-linear. It is particularly useful when a linear model is insufficient to capture the underlying pattern in the data. By including higher-order terms of the independent variable, polynomial regression can model more complex relationships and provide a better fit to the data. However, it is important to choose the degree of the polynomial carefully to avoid overfitting. For example, if the variable `i` represents the degree of the polynomial, a higher value of `i` can capture more complex patterns but also increases the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 25) - Polynomial regression is used when the relationship between the independent variable and the dependent variable is non-linear. It is particularly useful when a linear model is insufficient to capture the underlying pattern in the data. By including higher-order terms of the independent variable, polynomial regression can model more complex relationships and provide a better fit to the data. However, it is important to choose the degree of the polynomial carefully to avoid overfitting. For example, if the variable `i` represents the degree of the polynomial, a higher value of `i` can capture more complex patterns but also increases the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 26) - What is the general equation for polynomial regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans 26) - In general, polynomial models are of the form\n",
    "y = f ( x ) = β 0 + β 1 x + β 2 x^2 + β 3 x^3 + … + β d x^d + ϵ ,\n",
    " \n",
    "where  \n",
    "d is called the degree of the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 27) - Can polynomial regression be applied to multiple variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "Ans 27) - Yes, polynomial regression can be applied to multiple variables. This is known as multivariate polynomial regression. In this case, the model includes polynomial terms for each independent variable as well as interaction terms between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 28) - What are the limitations of polynomial regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 28) - The limitations of polynomial regression include:\n",
    "\n",
    "1. **Overfitting**: Polynomial regression can easily overfit the data, especially with higher-degree polynomials. Overfitting occurs when the model captures noise in the data rather than the underlying relationship, leading to poor generalization to new data.\n",
    "\n",
    "2. **Extrapolation**: Polynomial regression models can produce unreliable predictions when extrapolating beyond the range of the training data. The polynomial curve can behave unpredictably outside the observed data range.\n",
    "\n",
    "3. **Multicollinearity**: Higher-degree polynomial terms can introduce multicollinearity, where the predictor variables become highly correlated. This can make the model coefficients unstable and difficult to interpret.\n",
    "\n",
    "4. **Complexity**: As the degree of the polynomial increases, the model becomes more complex and harder to interpret. Higher-degree polynomials can result in a model that is difficult to understand and explain.\n",
    "\n",
    "5. **Computational Cost**: Fitting a high-degree polynomial regression model can be computationally expensive, especially with large datasets. The increased number of polynomial terms can lead to longer training times and higher computational requirements.\n",
    "\n",
    "6. **Sensitivity to Outliers**: Polynomial regression models can be highly sensitive to outliers. Outliers can disproportionately influence the shape of the polynomial curve, leading to a poor fit for the majority of the data points.\n",
    "\n",
    "7. **Choice of Degree**: Selecting the appropriate degree of the polynomial is crucial. A degree that is too low may underfit the data, while a degree that is too high may overfit. Choosing the right degree often requires experimentation and validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 29) - What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 29) - The methods that can be used to evaluate model fit when selecting the degree of a polynomial include:\n",
    "\n",
    "1. **Cross-Validation**: Cross-validation techniques, such as k-fold cross-validation, can be used to assess the model's performance on different subsets of the data. This helps to ensure that the model generalizes well to unseen data and avoids overfitting.\n",
    "\n",
    "2. **Adjusted R²**: Adjusted R² adjusts the R² value based on the number of predictors in the model. It provides a more accurate measure of model fit by penalizing the addition of unnecessary polynomial terms.\n",
    "\n",
    "3. **AIC and BIC**: The Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) are metrics that balance model fit and complexity. Lower values of AIC and BIC indicate a better model fit with fewer parameters.\n",
    "\n",
    "4. **Residual Analysis**: Analyzing the residuals (the differences between observed and predicted values) can help identify patterns that indicate poor model fit. Residual plots can reveal issues such as heteroscedasticity or non-linearity.\n",
    "\n",
    "5. **Validation Set**: Splitting the data into training and validation sets allows for the evaluation of model performance on a separate validation set. This helps to assess how well the model generalizes to new data.\n",
    "\n",
    "6. **Mean Squared Error (MSE)**: MSE measures the average squared difference between observed and predicted values. Lower MSE values indicate better model fit.\n",
    "\n",
    "7. **Visual Inspection**: Plotting the polynomial regression curve against the data points can provide a visual assessment of how well the model fits the data. This can help identify underfitting or overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 30) - Why is visualization important in polynomial regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Ans 30) - Visualization is important in polynomial regression for several reasons:\n",
    "\n",
    "1. **Understanding Relationships**: Visualization helps to understand the relationship between the independent and dependent variables. By plotting the polynomial regression curve along with the data points, you can see how well the model fits the data and whether it captures the underlying pattern.\n",
    "\n",
    "2. **Identifying Overfitting or Underfitting**: Visualization allows you to identify if the model is overfitting or underfitting the data. An overfitted model will have a curve that is too complex and follows the noise in the data, while an underfitted model will have a curve that is too simple and fails to capture the underlying trend.\n",
    "\n",
    "3. **Detecting Outliers**: Visualization helps to detect outliers that may disproportionately influence the polynomial regression model. Outliers can be identified as data points that deviate significantly from the fitted curve.\n",
    "\n",
    "4. **Communicating Results**: Visualization is a powerful tool for communicating the results of the polynomial regression analysis to others. It provides a clear and intuitive way to present the model's performance and the relationship between variables.\n",
    "\n",
    "5. **Model Comparison**: Visualization allows for the comparison of different polynomial regression models with varying degrees. By plotting multiple curves, you can visually assess which model provides the best fit to the data.\n",
    "\n",
    "Overall, visualization is a crucial step in the polynomial regression analysis process, as it provides valuable insights into the model's performance and helps to ensure that the model accurately represents the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques 31) - How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pip install scikit-learn pandas matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([1, 4, 9, 16, 25])\n",
    "\n",
    "# Generate polynomial features\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Predict using the model\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X, y, color='blue', label='Original data')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial fit')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
